{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Project 3] 10 digits classification - Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by **loading** our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pd.read_csv('features.txt')\n",
    "labels = pd.read_csv('labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated in the subject it is necessary to **replace** the \"10\" with 0 in the dataset. <br>\n",
    "To do this we use the function `replace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.rename(columns = {'10' : 'actual_value'}, inplace = True)\n",
    "labels.replace(10,0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the `scikit learn` method called `train_test_split` to split the datas into a **train** and a **test** set <br>\n",
    "Here we're using a test set representing 20% of our dataset. <br>\n",
    "this method automaticaly suffles the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image, labels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train.actual_value)\n",
    "y_test = pd.get_dummies(y_test.actual_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the neural network, the number of nodes for each layer (input, hidden, output)must be given.<br>\n",
    "After those informations, the constructor will initialize various things : \n",
    "* A Matrix of weights from input to hidden layer : `weight_ih`\n",
    "* A Matrix of weights from hidden to output layer : `weight_ho`\n",
    "* A Matrix of bias for the hidden layer : `bias_h`\n",
    "* A Matrix of bias for the output layer : `bias_o`\n",
    "* A learning initialized abitrary : `learningRate`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and score method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three main methods to implement:\n",
    "* feedforward: a function that will permit to obtain a prediction from a single input of the 400 pixels\n",
    "* train: A method that will take the input images and their labels from the train set as argument, considering we are doing supervised learning\n",
    "* score: A method that will take the input images and their labels from the test set as argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedforward method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to implement the feedforward method. <br>\n",
    "To do that we need to calculate the activations of the hidden and the output layers. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Hiden \\, Layer =  \\sigma \\, (weight\\_ih . Input \\, layer + bias\\_h)$ <br>\n",
    "$Output \\, Layer =  \\sigma \\, (weight\\_ho . Input \\, layer + bias\\_o)$ <br>\n",
    "> Where $\\sigma$ represents the sigmoid function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll take the output layer's activations as the output of this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we need to implement the train function. <br>\n",
    "we begin by computing the errors of the output (`output_errors`) and the hidden (`hidden_errors`) layers by those formulas :  <br>\n",
    "\n",
    "$Output\\_errors = labels - outputs$ <br>\n",
    "$Hidden\\_errors = weight\\_ho^t . Output\\_errors$\n",
    "\n",
    "> Here the `.` represents a matricial product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the errors for each layers we can compute the **gradients** in order to obtain the value by which we are going to correct our **weights** (`weight_ih_deltas` and `weight_ho_deltas`)  and **biases** (`hidden_gradients` and `output_gradients`). <br>\n",
    "To do this we will use linear regression formulas ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Weight\\_ho\\_deltas  = learning\\, rate \\times output\\_errors \\, \\times \\, \\sigma'(Output \\, Layer) \\, . \\, Hiden \\, Layer \\, ^t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Weight\\_ih\\_deltas  = learning\\, rate \\times hidden\\_errors \\, \\times \\, \\sigma'(hidden \\, activation) \\, . \\, Input \\, Layer \\, ^t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$hidden\\_gradients  = learning\\, rate \\times hidden\\_errors \\, \\times \\, \\sigma'(Hiden \\, Layer)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$output\\_gradients  = learning\\, rate \\times output\\_error \\, \\times \\, \\sigma'(Input \\, Layer)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here $\\sigma'$ reprensents the derivative of the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of the train method is to **update** our variables by adding the gradient we just calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$weight\\_ih = weight\\_ih + Weight\\_ih\\_deltas$<br>\n",
    "$weight\\_ho = weight\\_ho + Weight\\_ho\\_deltas$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$bias\\_h = bias\\_h + hidden\\_gradients$ <br>\n",
    "$bias\\_o = bias\\_o + output\\_gradients$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score method permits to compute the **accuracy** of the model on a train set <br>\n",
    "To do that we're just taking the **maximum value** of our outputs and stating that it's our predicted value <br>\n",
    "Then we build an array that compares `actual` and `predicted` value.\n",
    "We add a **one** to the array if the predicted value is equal to the actual one and **zero** if not <br>\n",
    "\n",
    "After that we just have to return following result:\n",
    "\n",
    "$Accuracy = \\frac{one's \\, occurences}{array's \\, size}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, nb_input_nodes, nb_hiden_nodes, nb_output_nodes):\n",
    "        \n",
    "        #Seting each layer size\n",
    "        self.nb_input_nodes = nb_input_nodes\n",
    "        self.nb_hiden_nodes = nb_hiden_nodes\n",
    "        self.nb_output_nodes = nb_output_nodes\n",
    "        \n",
    "        #Seting weight matrix\n",
    "        self.weight_ih = np.random.rand(self.nb_hiden_nodes, self.nb_input_nodes)\n",
    "        self.weight_ho = np.random.rand(self.nb_output_nodes, self.nb_hiden_nodes)\n",
    "        \n",
    "        #Seting learningRate\n",
    "        self.learningRate = 0.7\n",
    "        \n",
    "        #Seting Bias\n",
    "        self.bias_h = np.random.rand(nb_hiden_nodes, 1)*5\n",
    "        self.bias_o = np.random.rand(nb_output_nodes, 1)*5\n",
    "        \n",
    "    # input must have (nb_input_nodes, 1) as shape\n",
    "    def feedforward(self, input):\n",
    "        self.z_hiden_activation = np.dot(self.weight_ih, input)\n",
    "        self.z_hiden_activation += self.bias_h\n",
    "        self.hiden_activation = sigmoid(self.z_hiden_activation)\n",
    "        \n",
    "        self.z_output_activation = np.dot(self.weight_ho, self.hiden_activation)\n",
    "        self.z_output_activation += self.bias_o\n",
    "        self.output_activation = sigmoid(self.z_output_activation)\n",
    "        \n",
    "        return self.output_activation\n",
    "    \n",
    "    def train(self, inputs, labels):\n",
    "        \n",
    "        #Calculate the errors\n",
    "        outputs = self.feedforward(inputs)\n",
    "        output_errors = labels - outputs\n",
    "        hiden_errors = np.dot(self.weight_ho.T, output_errors)\n",
    "        \n",
    "        #Calculate the gradient for output layer\n",
    "        gradients = dsigmoid(outputs)\n",
    "        gradients = gradients * output_errors\n",
    "        gradients = gradients * self.learningRate\n",
    "        \n",
    "        #Calculate deltas for ho weights\n",
    "        weight_ho_deltas = np.dot(gradients, self.hiden_activation.T)\n",
    "\n",
    "        #Adjusting ho weights and bias\n",
    "        self.weight_ho += weight_ho_deltas\n",
    "        self.bias_o += gradients\n",
    "        \n",
    "        #Calculate the gradient for hiden layer\n",
    "        hiden_gradients = dsigmoid(self.hiden_activation)\n",
    "        hiden_gradients = hiden_gradients * hiden_errors\n",
    "        hiden_gradients = hiden_gradients * self.learningRate\n",
    "        \n",
    "        #Calculate deltas for ih weights\n",
    "        weight_ih_deltas = np.dot(hiden_gradients, inputs.T)\n",
    "\n",
    "        #Adjusting ih weights and bias\n",
    "        self.weight_ih += weight_ih_deltas\n",
    "        self.bias_h += hiden_gradients\n",
    "        \n",
    "        return (1/output_errors.shape[0]) * ((output_errors*output_errors).sum())\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        random_list = random.sample(range(0, y_test.shape[0]), y_test.shape[0])\n",
    "        prediction_count = []\n",
    "        for i in random_list:\n",
    "            \n",
    "            prediction = self.feedforward(X_test.values[i].reshape(400,1))\n",
    "            actual = y_test.values[i]\n",
    "            \n",
    "            predicted_value = np.where(prediction == prediction.max())[0][0]\n",
    "            actual_value = np.where(actual == actual.max())[0][0]\n",
    "            \n",
    "            if(predicted_value == actual_value):\n",
    "                prediction_count.append(1)\n",
    "        \n",
    "            else:\n",
    "                prediction_count.append(0)\n",
    "            \n",
    "            np_prediction_count = np.array(prediction_count)\n",
    "            accuracy = np_prediction_count.sum()/np_prediction_count.size\n",
    "            print(str(np_prediction_count.size) + ' / ' + str(y_test.shape[0]), end ='\\r')\n",
    "            \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is up! <br>\n",
    "Now we'll test it on the digits classification usecase <br>\n",
    "To do that we'll use `400` as the number composing the input layer giving that we have 400 pixels in each image. <br>\n",
    "We'll use `10` output nodes as our 10 different possible values <br>\n",
    "We use arbitrary `35` nodes for the hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `sample` method to suffle our data before training our model with all of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3998/3999\tMSE = 0.13659230947698517052\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "n = NeuralNetwork(400, 35, 10)\n",
    "\n",
    "loop = 0\n",
    "\n",
    "l = random.sample(range(0, y_train.shape[0]), y_train.shape[0])\n",
    "\n",
    "for i in l:\n",
    "    curr_img = X_train.values[l[i]].reshape(400,1)\n",
    "    curr_label = y_train.values[l[i]].reshape(10,1)\n",
    "    MSE = n.train(curr_img, curr_label)\n",
    "    print (str(loop) + '/' + str(X_train.shape[0]) + '\\tMSE = ' + str(MSE), end='\\r')\n",
    "    loop = loop+1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `score` method to compute the **accuracy** of our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 / 1000\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.score(X_test, y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-ec98a7a3c25f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[0;32m   1850\u001b[0m     \"\"\"\n\u001b[0;32m   1851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "print(classification_report(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a different resulting accuracy depending on the shuffle. <br>\n",
    "it fluctuate from 75% to 85% which is prertty good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing our model accuracy to scikit learn's one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn's neural network does not work the same way. <br>\n",
    "Indeed it will feedforward all the datasets before computing the errors. <br>\n",
    "the datasets will be iterated several times.\n",
    "> You can configure this value with `max_iter` attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=35, learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(35), activation='logistic', solver='adam', max_iter=100 )\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704267740341732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "# print(classification_report(y_train,predict_train))\n",
    "print(precision_score(y_train,predict_train, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn's neural network model gives us a 97% accuracy score. <br>\n",
    "This value could be explained by the way this neural network train the model as explained above firstly and by the learning rate which is realy low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 / 1000\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.score(X_test, y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
